#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIï¼ä»®æƒ³é€šè²¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è‡ªå‹•è¦ç´„ã—ã¦ Obsidian ã«ä¿å­˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å€‹äººæƒ…å ±ãƒ»ã‚­ãƒ¼é¡ã¯ .env ã«ç½®ãå‰æï¼ˆ.gitignore ã« .env ã‚’å…¥ã‚Œã¦ãŠãã“ã¨ï¼‰
"""

import os
import feedparser
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from dotenv import load_dotenv
import openai

# --------------------------------------------------
# 1) .env ã‚’èª­ã¿è¾¼ã‚€
# --------------------------------------------------
load_dotenv()  # åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã® .env ã‚’ãƒ­ãƒ¼ãƒ‰

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")       # å¿…é ˆ
SAVE_DIR        = os.getenv("SAVE_DIR")            # å¿…é ˆ
NICKNAME        = os.getenv("NICKNAME")            # å¿…é ˆ
PROFILE         = os.getenv("PROFILE")             # å¿…é ˆ

# RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šå¯
AI_FEEDS = [u.strip() for u in os.getenv("AI_FEEDS", "").split(",") if u.strip()]
CRYPTO_FEEDS = os.getenv("CRYPTO_FEEDS", "").split(",")

if not all([OPENAI_API_KEY, SAVE_DIR, NICKNAME, PROFILE]):
    raise ValueError("å¿…è¦ãªç’°å¢ƒå¤‰æ•°ï¼ˆOPENAI_API_KEY, SAVE_DIR, NICKNAME, PROFILEï¼‰ãŒ .env ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

# --------------------------------------------------
# 2) OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
# --------------------------------------------------
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# --------------------------------------------------
# 3) ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™
# --------------------------------------------------
os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------------------------------
# 4) ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—è¨­å®š
# --------------------------------------------------
KEYWORDS_AI     = ["ai", "äººå·¥çŸ¥èƒ½", "ç”Ÿæˆai", "chatgpt", "gpt", "openai"]
KEYWORDS_CRYPTO = ["ä»®æƒ³é€šè²¨", "æš—å·è³‡ç”£", "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³", "ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³", "crypto"]

# --------------------------------------------------
# 5) RSS å–å¾—ï¼†ãƒ•ã‚£ãƒ«ã‚¿
# --------------------------------------------------
def fetch_feed(feed_urls, keywords):
    """RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰æœ€å¤§ 5 ä»¶ã®è¨˜äº‹ã‚’å–å¾—"""
    results = []
    for url in filter(None, feed_urls):       # ç©ºæ–‡å­—ã‚’é™¤å¤–
        url = url.strip()
        feed = feedparser.parse(url)
        for entry in feed.entries[:20]:
            title   = entry.title.lower()
            summary = getattr(entry, "summary", "").lower()
            if any(k in title or k in summary for k in keywords):
                results.append(
                    {
                        "title": entry.title,
                        "url":   entry.link,
                        "published": getattr(entry, "published", "ä¸æ˜")
                    }
                )
    # æ–°ã—ã„é †ã«ä¸¦ã³æ›¿ãˆï¼ˆpublished ãŒç„¡ã„å ´åˆã¯ãã®ã¾ã¾ï¼‰
    results.sort(key=lambda x: x["published"], reverse=True)
    return results[:5]

# --------------------------------------------------
# 6) æœ¬æ–‡ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆ2000 æ–‡å­—ä¸Šé™ï¼‰
# --------------------------------------------------
def fetch_text(url: str) -> str:
    try:
        res = requests.get(url, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        paragraphs = [p.get_text(" ", strip=True) for p in soup.find_all("p")]
        return "\n".join(paragraphs)[:2000]
    except Exception as e:
        return f"(æœ¬æ–‡å–å¾—å¤±æ•—: {e})"

# --------------------------------------------------
# 7) ChatGPT ã§è¦ç´„
# --------------------------------------------------
def gpt_summary(text: str) -> str:
    prompt = f"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’æ—¥æœ¬èªã§200å­—ä»¥å†…ã«è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n{text}"
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=300,
        temperature=0.7,
    )
    return res.choices[0].message.content.strip()

# --------------------------------------------------
# 8) ChatGPT ã§è¡Œå‹•ææ¡ˆ
# --------------------------------------------------
def gpt_suggestion(summary: str) -> str:
    prompt = (
        f"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã«å¯¾ã—ã¦ã€{PROFILE} ã«å‘ã‘ãŸå…·ä½“çš„ãªè¡Œå‹•ææ¡ˆã‚’"
        "3ã¤ãƒªã‚¹ãƒˆå½¢å¼ã§å‡ºã—ã¦ãã ã•ã„ã€‚\n"
        "ç™ºä¿¡ã€å‰¯æ¥­ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åŒ–ã€åç›ŠåŒ–ãªã©ã«ã¤ãªãŒã‚‹ã€å®Ÿè¡Œå¯èƒ½ã§å°‘ã—æŒ‘æˆ¦çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"{summary}"
    )
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=500,
        temperature=0.8,
    )
    return res.choices[0].message.content.strip()

# --------------------------------------------------
# 9) ã‚¿ã‚°è‡ªå‹•ç”Ÿæˆ
# --------------------------------------------------
def tag_from_suggestion(suggestion: str) -> str:
    s = suggestion.lower()
    tags = set()
    if "ai" in s or "äººå·¥çŸ¥èƒ½" in s: tags.add("#AI")
    if any(k in s for k in ["ä»®æƒ³é€šè²¨", "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³", "æš—å·è³‡ç”£"]): tags.add("#ä»®æƒ³é€šè²¨")
    tags.update({"#å‰¯æ¥­", "#åç›ŠåŒ–æ¡ˆ"})
    if "note"      in s: tags.add("#noteæ¡ˆ")
    if "twitter"   in s or "xã§" in s or "ãƒã‚¹ãƒˆ" in s: tags.add("#Xæ¡ˆ")
    if "youtube"   in s: tags.add("#YouTubeæ¡ˆ")
    if "kindle"    in s: tags.add("#Kindleæ¡ˆ")
    if "udemy"     in s: tags.add("#Udemyæ¡ˆ")
    if "stand.fm"  in s or "éŸ³å£°é…ä¿¡" in s: tags.add("#éŸ³å£°é…ä¿¡æ¡ˆ")
    return " ".join(sorted(tags))

# --------------------------------------------------
# 10) Markdown ç”Ÿæˆ
# --------------------------------------------------
def process_articles(articles, header):
    section = [f"## {header}\n"]
    for idx, art in enumerate(articles, 1):
        text       = fetch_text(art["url"])
        summary    = gpt_summary(text)
        suggestion = gpt_suggestion(summary)
        tags       = tag_from_suggestion(suggestion)

        section.append(f"### ã€”{idx}ã€• {art['title']}")
        section.append(f"- **å…¬é–‹æ—¥:** {art['published']}")
        section.append(f"- **URL:** {art['url']}\n")
        section.append(f"**è¦ç´„:** {summary}\n")
        section.append(f"**{NICKNAME}ã¸ã®ææ¡ˆ:**\n{suggestion}\n")
        section.append(f"{tags}\n")
    return section

# --------------------------------------------------
# 11) ãƒ¡ã‚¤ãƒ³å‡¦ç†
# --------------------------------------------------
def main():
    ai_articles     = fetch_feed(AI_FEEDS, KEYWORDS_AI)
    crypto_articles = fetch_feed(CRYPTO_FEEDS, KEYWORDS_CRYPTO)

    today    = datetime.now().strftime("%Y-%m-%d")
    filename = f"news_{datetime.now():%Y%m%d}.md"

    content = [f"# {today} ã® AIãƒ»ä»®æƒ³é€šè²¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚\n"]
    content += process_articles(ai_articles, "ğŸ”· AI ãƒ‹ãƒ¥ãƒ¼ã‚¹")
    content += process_articles(crypto_articles, "ğŸ”¶ ä»®æƒ³é€šè²¨ãƒ‹ãƒ¥ãƒ¼ã‚¹")

    with open(os.path.join(SAVE_DIR, filename), "w", encoding="utf-8") as f:
        f.write("\n".join(content))

    print(f"âœ… ä¿å­˜å®Œäº†: {filename}")

# --------------------------------------------------
if __name__ == "__main__":
    main()

